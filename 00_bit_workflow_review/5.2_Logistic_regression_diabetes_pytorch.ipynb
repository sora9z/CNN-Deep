{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.10 64-bit ('TF2': conda)",
   "display_name": "Python 3.6.10 64-bit ('TF2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "0852b15a40ba772cc6cccde9ee3e0692fec73481972f7fa88d7df0aedb40ab85"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(759, 8) (759, 1)\n"
    }
   ],
   "source": [
    "# Lab 5 Logistic Regression Classifier\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "torch.manual_seed(000)\n",
    "\n",
    "xy=np.loadtxt('../00_data/data-03-diabetes.csv',delimiter=',',dtype=np.float32)\n",
    "x_data=xy[:,:-1]\n",
    "y_data=xy[:,[-1]]\n",
    "\n",
    "if y_data is None:\n",
    "    print('data load failed')\n",
    "    sys.exit()\n",
    "# Make sure the shape and data are OK\n",
    "print(x_data.shape,y_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 0.65017927\n200 0.62169886\n400 0.60644895\n600 0.594258\n800 0.58366597\n1000 0.57431483\n1200 0.566016\n1400 0.55862445\n1600 0.55201906\n1800 0.546096\n2000 0.54076785\n2200 0.5359593\n2400 0.53160673\n2600 0.52765524\n2800 0.5240578\n3000 0.520774\n3200 0.51776904\n3400 0.5150125\n3600 0.5124781\n3800 0.51014316\n4000 0.5079875\n4200 0.5059936\n4400 0.504146\n4600 0.50243086\n4800 0.5008364\n5000 0.49935165\n5200 0.4979673\n5400 0.49667442\n5600 0.49546564\n5800 0.4943342\n6000 0.4932735\n6200 0.49227828\n6400 0.49134338\n6600 0.4904646\n6800 0.4896373\n7000 0.4888579\n7200 0.48812282\n7400 0.4874292\n7600 0.48677412\n7800 0.48615468\n8000 0.48556864\n8200 0.4850139\n8400 0.4844881\n8600 0.48398986\n8800 0.48351708\n9000 0.48306814\n9200 0.48264164\n9400 0.48223636\n9600 0.48185065\n9800 0.48148364\n10000 0.48113415\n\nHypothesis: &lt;built-in method numpy of Tensor object at 0x0000021E0E8FC048&gt; \nCorrect(Y): &lt;built-in method numpy of Tensor object at 0x0000021E0E8FC8B8&gt; \nAccuracy: tensor(0.7694)\n"
    }
   ],
   "source": [
    "# Set X,y variable\n",
    "X=Variable(torch.from_numpy(x_data))\n",
    "Y=Variable(torch.from_numpy(y_data))\n",
    "\n",
    "#Hypodhesis using sigmoid\n",
    "linear=torch.nn.Linear(8,1,bias=True)\n",
    "sigmoid=torch.nn.Sigmoid()\n",
    "model=torch.nn.Sequential(linear,sigmoid)\n",
    "\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis=model(X)\n",
    "    #cost, loss function\n",
    "    cost=-(Y*torch.log(hypothesis)+(1-Y)*torch.log(1-hypothesis)).mean()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step%200==0:\n",
    "        print(step,cost.data.numpy())\n",
    "\n",
    "# Accuracy computation\n",
    "predicted=(model(X).data>0.5).float()\n",
    "accuracy=(predicted==Y.data).float().mean()\n",
    "print(\"\\nHypothesis:\",hypothesis.data.numpy,\"\\nCorrect(Y):\",predicted.data.numpy,\"\\nAccuracy:\",accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}