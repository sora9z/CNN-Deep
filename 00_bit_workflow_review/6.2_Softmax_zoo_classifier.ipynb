{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.10 64-bit ('TF1': conda)",
   "display_name": "Python 3.6.10 64-bit ('TF1': conda)",
   "metadata": {
    "interpreter": {
     "hash": "cd611deae2f39ac3c8cd4a9874d76c06eda9b6eaba69760e6b49bdda116ee039"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 6.2 Softmax_zoo_classifier\n",
    "\n",
    "## (1) 실습 목적\n",
    "- 파일입력 sotfmax 구현 함수를 익힌다.\n",
    "## (2) 사용한 API및 간단한 설명\n",
    "\n",
    "- tf.nn.softmax_cross_entropy_with_logits\n",
    "- tf.argmax\n",
    "\n",
    "## Softmax 동작\n",
    "- cost_i = tf.nn.softmax_cross_entropy_with_logits(ligits=ligits,labels=Y_one_hot)\n",
    "    - logits=tf.matmul(X,W)+b 에서 바로 cost 함수를 얻는다.\n",
    "    - hypothesis=tf.nn.softmax(logits) 은 사용하지않고 예츨할 때에만 사용된다.\n",
    "\n",
    "- cost=tf.reduce_mean(cost_t)\n",
    "    - 코스트 함수의 평균을 구한다.\n",
    "- optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "    - 학습을 진행한다.\n",
    "- prediction=tf.argmax(hypothesis,1)\n",
    "    - 예측을 진행한다.\n",
    "- correct_prediction=tf.equal(prediction,tf.argmax(Y_one_hot,1))\n",
    "    - 정답과 예측을 비교한다.\n",
    "- accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    - 정확도를 구한다.\n",
    "- 출력을 one hot encoding 처리한다.</br>\n",
    "    X(101,6)</br>\n",
    "    Y(101,1)</br>\n",
    "    one_hot Tensor(\"one_hot\",shape=(?,1,7),dtype=float32)</br>\n",
    "    reshape Tensoe(\"Reshape:0\",shape=(?,7),dtype=float32)</br>\n",
    "    \n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(101, 16) (101, 1)\n",
      "one_hot Tensor(\"one_hot_14:0\", shape=(?, 1, 7), dtype=float32)\n",
      "reshape Tensor(\"Reshape_10:0\", shape=(?, 7), dtype=float32)\n",
      "Step:     0\tLoss: 1.691\tAcc: 35.64%\n",
      "Step:   100\tLoss: 0.494\tAcc: 87.13%\n",
      "Step:   200\tLoss: 0.334\tAcc: 94.06%\n",
      "Step:   300\tLoss: 0.257\tAcc: 96.04%\n",
      "Step:   400\tLoss: 0.210\tAcc: 96.04%\n",
      "Step:   500\tLoss: 0.178\tAcc: 97.03%\n",
      "Step:   600\tLoss: 0.155\tAcc: 99.01%\n",
      "Step:   700\tLoss: 0.137\tAcc: 99.01%\n",
      "Step:   800\tLoss: 0.123\tAcc: 99.01%\n",
      "Step:   900\tLoss: 0.112\tAcc: 100.00%\n",
      "Step:  1000\tLoss: 0.102\tAcc: 100.00%\n",
      "Step:  1100\tLoss: 0.094\tAcc: 100.00%\n",
      "Step:  1200\tLoss: 0.088\tAcc: 100.00%\n",
      "Step:  1300\tLoss: 0.082\tAcc: 100.00%\n",
      "Step:  1400\tLoss: 0.077\tAcc: 100.00%\n",
      "Step:  1500\tLoss: 0.072\tAcc: 100.00%\n",
      "Step:  1600\tLoss: 0.068\tAcc: 100.00%\n",
      "Step:  1700\tLoss: 0.064\tAcc: 100.00%\n",
      "Step:  1800\tLoss: 0.061\tAcc: 100.00%\n",
      "Step:  1900\tLoss: 0.058\tAcc: 100.00%\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n"
     ]
    }
   ],
   "source": [
    "# Lab 6-2 Softmax_zoo_classifier\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "tf.set_random_seed(000)\n",
    "xy=np.loadtxt('../00_data/data-04-zoo.csv',delimiter=',',dtype=np.float32)\n",
    "x=xy[:,0:-1]\n",
    "y=xy[:,[-1]]\n",
    "\n",
    "# Check data load is OK\n",
    "\n",
    "if x is None or y is None:\n",
    "    print('data load failed')\n",
    "    sys.exit()\n",
    "print(x.shape,y.shape)\n",
    "\n",
    "nb_classes=7 #0~6\n",
    "X=tf.placeholder(tf.float32,[None,16])\n",
    "Y=tf.placeholder(tf.int32,[None,1])\n",
    "\n",
    "Y_one_hot=tf.one_hot(Y,nb_classes) #one hot\n",
    "print('one_hot',Y_one_hot)\n",
    "Y_one_hot=tf.reshape(Y_one_hot,[-1,nb_classes]) # Rank 2로 reshape , -1 means that the length in that dimension is inferred. \n",
    "print(\"reshape\",Y_one_hot)\n",
    "\n",
    "W=tf.Variable(tf.random_uniform([16,nb_classes]),name='weight')\n",
    "b=tf.Variable(tf.random_uniform([nb_classes]),name='bias')\n",
    "\n",
    "logits=tf.matmul(X,W)+b\n",
    "hypothesis=tf.nn.softmax(logits)\n",
    "\n",
    "#Cross entropy cost/loss\n",
    "cost_i=tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=Y_one_hot)\n",
    "cost=tf.reduce_mean(cost_i)\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction=tf.argmax(hypothesis,1)\n",
    "correct_prediction=tf.equal(prediction,tf.argmax(Y_one_hot,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "'''\n",
    "#Launch graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2000):\n",
    "        sess.run(optimizer,feed_dict={X:x,Y:y})\n",
    "        if step%100==0:\n",
    "            loss,acc=sess.run([cost,accuracy],feed_dict={X:x,Y:y})\n",
    "            print(\"Step:{:.5f}\\tLoss:{:.3f}\\tAcc:{:.2f}\".format(step,loss,acc))\n",
    "        # Let's see if we can predict\n",
    "        pred=sess.run(prediction,feed_dict={X:x})\n",
    "        # y_data: (N,1)=flatten=>(N,)matches pred.shap\n",
    "        for p,y in zip(pred,y.flatten()):\n",
    "            print(\"[{}]Prediction:{} True Y: {}\".format(p==int(y),p,int(y)))\n",
    "'''\n",
    "# Launch graph\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "    for step in range(2000):\n",
    "\n",
    "        sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "\n",
    "        if step % 100 == 0:\n",
    "\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "\n",
    "                                 X: x, Y: y})\n",
    "\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n",
    "\n",
    "                step, loss, acc))\n",
    "\n",
    "\n",
    "    # Let's see if we can predict\n",
    "\n",
    "    pred = sess.run(prediction, feed_dict={X: x})\n",
    "\n",
    "    # y_data: (N,1) = flatten => (N, ) matches pred.shape\n",
    "\n",
    "    for p, y in zip(pred, y.flatten()):\n",
    "\n",
    "        print(\"[{}] Prediction: {} True Y: {}\".format(p == int(y), p, int(y)))\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "## tf.nn.softmax_cross_entropy_with_logits(logits,labels,azis=-1,name=None)\n",
    "\n",
    "Measures the probability error in discrete classification tasks in which the classes are mutually exclusive </br>\n",
    "(each entry is in exactly one class). For example, each CIFAR-10 image is labeled with one and only one label:</br>\n",
    " an image can be a dog or a truck, but not both."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}