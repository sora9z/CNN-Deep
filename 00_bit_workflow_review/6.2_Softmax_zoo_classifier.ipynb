{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.10 64-bit ('TF1': conda)",
   "display_name": "Python 3.6.10 64-bit ('TF1': conda)",
   "metadata": {
    "interpreter": {
     "hash": "cd611deae2f39ac3c8cd4a9874d76c06eda9b6eaba69760e6b49bdda116ee039"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 6.2 Softmax_zoo_classifier\n",
    "\n",
    "## (1) 실습 목적\n",
    "- 파일입력 sotfmax 구현 함수를 익힌다.\n",
    "## (2) 사용한 API및 간단한 설명\n",
    "\n",
    "- tf.nn.softmax_cross_entropy_with_logits\n",
    "- tf.argmax\n",
    "\n",
    "## Softmax 동작\n",
    "- cost_i = tf.nn.softmax_cross_entropy_with_logits(ligits=ligits,labels=Y_one_hot)\n",
    "    - logits=tf.matmul(X,W)+b 에서 바로 cost 함수를 얻는다.\n",
    "    - hypothesis=tf.nn.softmax(logits) 은 사용하지않고 예츨할 때에만 사용된다.\n",
    "\n",
    "- cost=tf.reduce_mean(cost_t)\n",
    "    - 코스트 함수의 평균을 구한다.\n",
    "- optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "    - 학습을 진행한다.\n",
    "- prediction=tf.argmax(hypothesis,1)\n",
    "    - 예측을 진행한다.\n",
    "- correct_prediction=tf.equal(prediction,tf.argmax(Y_one_hot,1))\n",
    "    - 정답과 예측을 비교한다.\n",
    "- accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    - 정확도를 구한다.\n",
    "- 출력을 one hot encoding 처리한다.</br>\n",
    "    X(101,6)</br>\n",
    "    Y(101,1)</br>\n",
    "    one_hot Tensor(\"one_hot\",shape=(?,1,7),dtype=float32)</br>\n",
    "    reshape Tensoe(\"Reshape:0\",shape=(?,7),dtype=float32)</br>\n",
    "    \n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(101, 16) (101, 1)\n",
      "one_hot Tensor(\"one_hot:0\", shape=(?, 1, 7), dtype=float32)\n",
      "reshape Tensor(\"Reshape:0\", shape=(?, 7), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-1-179d3c435f79>:34: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Step:     0\tLoss: 2.997\tAcc: 1.98%\n",
      "Step:   100\tLoss: 0.485\tAcc: 88.12%\n",
      "Step:   200\tLoss: 0.326\tAcc: 91.09%\n",
      "Step:   300\tLoss: 0.251\tAcc: 94.06%\n",
      "Step:   400\tLoss: 0.206\tAcc: 95.05%\n",
      "Step:   500\tLoss: 0.175\tAcc: 98.02%\n",
      "Step:   600\tLoss: 0.152\tAcc: 98.02%\n",
      "Step:   700\tLoss: 0.135\tAcc: 99.01%\n",
      "Step:   800\tLoss: 0.121\tAcc: 100.00%\n",
      "Step:   900\tLoss: 0.110\tAcc: 100.00%\n",
      "Step:  1000\tLoss: 0.101\tAcc: 100.00%\n",
      "Step:  1100\tLoss: 0.093\tAcc: 100.00%\n",
      "Step:  1200\tLoss: 0.086\tAcc: 100.00%\n",
      "Step:  1300\tLoss: 0.080\tAcc: 100.00%\n",
      "Step:  1400\tLoss: 0.075\tAcc: 100.00%\n",
      "Step:  1500\tLoss: 0.071\tAcc: 100.00%\n",
      "Step:  1600\tLoss: 0.067\tAcc: 100.00%\n",
      "Step:  1700\tLoss: 0.063\tAcc: 100.00%\n",
      "Step:  1800\tLoss: 0.060\tAcc: 100.00%\n",
      "Step:  1900\tLoss: 0.057\tAcc: 100.00%\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n"
     ]
    }
   ],
   "source": [
    "# Lab 6-2 Softmax_zoo_classifier\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "tf.set_random_seed(000)\n",
    "xy=np.loadtxt('../00_data/data-04-zoo.csv',delimiter=',',dtype=np.float32)\n",
    "x=xy[:,0:-1]\n",
    "y=xy[:,[-1]]\n",
    "\n",
    "# Check data load is OK\n",
    "\n",
    "if x is None or y is None:\n",
    "    print('data load failed')\n",
    "    sys.exit()\n",
    "print(x.shape,y.shape)\n",
    "\n",
    "nb_classes=7 #0~6\n",
    "X=tf.placeholder(tf.float32,[None,16])\n",
    "Y=tf.placeholder(tf.int32,[None,1])\n",
    "\n",
    "Y_one_hot=tf.one_hot(Y,nb_classes) #one hot\n",
    "print('one_hot',Y_one_hot)\n",
    "Y_one_hot=tf.reshape(Y_one_hot,[-1,nb_classes]) # Rank 2로 reshape , -1 means that the length in that dimension is inferred. \n",
    "print(\"reshape\",Y_one_hot)\n",
    "\n",
    "W=tf.Variable(tf.random_uniform([16,nb_classes]),name='weight')\n",
    "b=tf.Variable(tf.random_uniform([nb_classes]),name='bias')\n",
    "\n",
    "logits=tf.matmul(X,W)+b\n",
    "hypothesis=tf.nn.softmax(logits)\n",
    "\n",
    "#Cross entropy cost/loss\n",
    "cost_i=tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=Y_one_hot)\n",
    "cost=tf.reduce_mean(cost_i)\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction=tf.argmax(hypothesis,1)\n",
    "correct_prediction=tf.equal(prediction,tf.argmax(Y_one_hot,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "'''\n",
    "#Launch graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2000):\n",
    "        sess.run(optimizer,feed_dict={X:x,Y:y})\n",
    "        if step%100==0:\n",
    "            loss,acc=sess.run([cost,accuracy],feed_dict={X:x,Y:y})\n",
    "            print(\"Step:{:.5f}\\tLoss:{:.3f}\\tAcc:{:.2f}\".format(step,loss,acc))\n",
    "        # Let's see if we can predict\n",
    "        pred=sess.run(prediction,feed_dict={X:x})\n",
    "        # y_data: (N,1)=flatten=>(N,)matches pred.shap\n",
    "        for p,y in zip(pred,y.flatten()):\n",
    "            print(\"[{}]Prediction:{} True Y: {}\".format(p==int(y),p,int(y)))\n",
    "'''\n",
    "# Launch graph\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"one hot :\",)\n",
    "\n",
    "\n",
    "    for step in range(2000):\n",
    "\n",
    "        sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "\n",
    "        if step % 100 == 0:\n",
    "\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "\n",
    "                                 X: x, Y: y})\n",
    "\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n",
    "\n",
    "                step, loss, acc))\n",
    "\n",
    "\n",
    "    # Let's see if we can predict\n",
    "\n",
    "    pred = sess.run(prediction, feed_dict={X: x})\n",
    "\n",
    "    # y_data: (N,1) = flatten => (N, ) matches pred.shape\n",
    "\n",
    "    for p, y in zip(pred, y.flatten()):\n",
    "\n",
    "        print(\"[{}] Prediction: {} True Y: {}\".format(p == int(y), p, int(y)))\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(101, 16) (101, 1)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "tf.placeholder() is not compatible with eager execution.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-038f1d781206>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m \u001b[1;31m#0~6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TF1\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m   2614\u001b[0m   \"\"\"\n\u001b[0;32m   2615\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2616\u001b[1;33m     raise RuntimeError(\"tf.placeholder() is not compatible with \"\n\u001b[0m\u001b[0;32m   2617\u001b[0m                        \"eager execution.\")\n\u001b[0;32m   2618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tf.placeholder() is not compatible with eager execution."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "tf.set_random_seed(000)\n",
    "xy=np.loadtxt('../00_data/data-04-zoo.csv',delimiter=',',dtype=np.float32)\n",
    "x=xy[:,0:-1]\n",
    "y=xy[:,[-1]]\n",
    "\n",
    "# Check data load is OK\n",
    "\n",
    "if x is None or y is None:\n",
    "    print('data load failed')\n",
    "    sys.exit()\n",
    "print(x.shape,y.shape)\n",
    "\n",
    "nb_classes=7 #0~6\n",
    "X=tf.placeholder(tf.float32,[None,16])\n",
    "Y=tf.placeholder(tf.int32,[None,1])\n",
    "\n",
    "Y_one_hot=tf.one_hot(Y,nb_classes) #one hot\n",
    "print('one_hot',Y_one_hot)\n",
    "Y_one_hot_reshape=tf.reshape(Y_one_hot,[-1,nb_classes]) # Rank 2로 reshape , -1 means that the length in that dimension is inferred. \n",
    "print(\"reshape\",Y_one_hot_reshape)\n",
    "sess=tf.Session()\n",
    "sess.run(Y_one_hot)\n"
   ]
  },
  {
   "source": [
    "## tf.nn.softmax_cross_entropy_with_logits(logits,labels,azis=-1,name=None)\n",
    "\n",
    "Measures the probability error in discrete classification tasks in which the classes are mutually exclusive </br>\n",
    "(each entry is in exactly one class). For example, each CIFAR-10 image is labeled with one and only one label:</br>\n",
    " an image can be a dog or a truck, but not both."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}