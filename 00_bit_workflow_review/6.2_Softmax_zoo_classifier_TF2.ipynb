{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.10 64-bit ('TF2': conda)",
   "display_name": "Python 3.6.10 64-bit ('TF2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "0852b15a40ba772cc6cccde9ee3e0692fec73481972f7fa88d7df0aedb40ab85"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 함수 설명\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "101 [==============================] - 0s 89us/sample - loss: 0.0353 - accuracy: 1.0000\n",
      "Epoch 817/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0354 - accuracy: 1.0000\n",
      "Epoch 818/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 819/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 820/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 821/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 822/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "101/101 [==============================] - 0s 79us/sample - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "101/101 [==============================] - 0s 79us/sample - loss: 0.0349 - accuracy: 1.0000\n",
      "Epoch 825/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0348 - accuracy: 1.0000\n",
      "Epoch 826/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0349 - accuracy: 1.0000\n",
      "Epoch 827/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0350 - accuracy: 1.0000\n",
      "Epoch 828/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0347 - accuracy: 1.0000\n",
      "Epoch 829/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0347 - accuracy: 1.0000\n",
      "Epoch 830/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0348 - accuracy: 1.0000\n",
      "Epoch 831/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0348 - accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "101/101 [==============================] - 0s 79us/sample - loss: 0.0348 - accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0345 - accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0345 - accuracy: 1.0000\n",
      "Epoch 835/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 836/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 837/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 839/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 840/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 841/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 842/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 843/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 844/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 845/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 847/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 848/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0340 - accuracy: 1.0000\n",
      "Epoch 850/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0340 - accuracy: 1.0000\n",
      "Epoch 851/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0340 - accuracy: 1.0000\n",
      "Epoch 852/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0338 - accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0339 - accuracy: 1.0000\n",
      "Epoch 854/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0339 - accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0337 - accuracy: 1.0000\n",
      "Epoch 856/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0338 - accuracy: 1.0000\n",
      "Epoch 857/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 858/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 860/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 861/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0337 - accuracy: 1.0000\n",
      "Epoch 862/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 864/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 865/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0334 - accuracy: 1.0000\n",
      "Epoch 866/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0333 - accuracy: 1.0000\n",
      "Epoch 867/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 868/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0334 - accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0330 - accuracy: 1.0000\n",
      "Epoch 871/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 872/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 873/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0330 - accuracy: 1.0000\n",
      "Epoch 874/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0330 - accuracy: 1.0000\n",
      "Epoch 875/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0328 - accuracy: 1.0000\n",
      "Epoch 876/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0330 - accuracy: 1.0000\n",
      "Epoch 877/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0328 - accuracy: 1.0000\n",
      "Epoch 878/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 879/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 880/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "101/101 [==============================] - 0s 79us/sample - loss: 0.0328 - accuracy: 1.0000\n",
      "Epoch 882/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0328 - accuracy: 1.0000\n",
      "Epoch 883/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 884/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0327 - accuracy: 1.0000\n",
      "Epoch 885/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 886/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 887/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 888/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 889/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 890/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 891/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 892/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0323 - accuracy: 1.0000\n",
      "Epoch 893/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0323 - accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 895/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0323 - accuracy: 1.0000\n",
      "Epoch 896/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 897/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 898/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 899/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 900/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0320 - accuracy: 1.0000\n",
      "Epoch 901/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0321 - accuracy: 1.0000\n",
      "Epoch 902/1000\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 903/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0321 - accuracy: 1.0000\n",
      "Epoch 905/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0320 - accuracy: 1.0000\n",
      "Epoch 906/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0321 - accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0320 - accuracy: 1.0000\n",
      "Epoch 908/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0320 - accuracy: 1.0000\n",
      "Epoch 909/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0318 - accuracy: 1.0000\n",
      "Epoch 910/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 911/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0318 - accuracy: 1.0000\n",
      "Epoch 912/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0317 - accuracy: 1.0000\n",
      "Epoch 914/1000\n",
      "101/101 [==============================] - 0s 168us/sample - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 915/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0318 - accuracy: 1.0000\n",
      "Epoch 916/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 917/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 918/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0317 - accuracy: 1.0000\n",
      "Epoch 919/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 920/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "101/101 [==============================] - 0s 158us/sample - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 922/1000\n",
      "101/101 [==============================] - 0s 148us/sample - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 923/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0314 - accuracy: 1.0000\n",
      "Epoch 924/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0314 - accuracy: 1.0000\n",
      "Epoch 925/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0314 - accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0313 - accuracy: 1.0000\n",
      "Epoch 928/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0311 - accuracy: 1.0000\n",
      "Epoch 931/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 932/1000\n",
      "101/101 [==============================] - 0s 148us/sample - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 933/1000\n",
      "101/101 [==============================] - 0s 148us/sample - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 934/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 935/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 936/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 937/1000\n",
      "101/101 [==============================] - 0s 158us/sample - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 938/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 939/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 940/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0308 - accuracy: 1.0000\n",
      "Epoch 941/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 942/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 943/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 944/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 945/1000\n",
      "101/101 [==============================] - 0s 465us/sample - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 946/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 947/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 948/1000\n",
      "101/101 [==============================] - 0s 178us/sample - loss: 0.0305 - accuracy: 1.0000\n",
      "Epoch 949/1000\n",
      "101/101 [==============================] - 0s 158us/sample - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 951/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0305 - accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 954/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 955/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 956/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 957/1000\n",
      "101/101 [==============================] - 0s 178us/sample - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 958/1000\n",
      "101/101 [==============================] - 0s 465us/sample - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 959/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 960/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 962/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "101/101 [==============================] - 0s 168us/sample - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 964/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 965/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 967/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 968/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 969/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 970/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 971/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 973/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 974/1000\n",
      "101/101 [==============================] - 0s 139us/sample - loss: 0.0297 - accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 976/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 977/1000\n",
      "101/101 [==============================] - 0s 158us/sample - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 978/1000\n",
      "101/101 [==============================] - 0s 148us/sample - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 979/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 980/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0297 - accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 982/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 985/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 986/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 987/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0294 - accuracy: 1.0000\n",
      "Epoch 988/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0294 - accuracy: 1.0000\n",
      "Epoch 989/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 990/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0294 - accuracy: 1.0000\n",
      "Epoch 991/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 992/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 993/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 994/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 995/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 996/1000\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 997/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 998/1000\n",
      "101/101 [==============================] - 0s 129us/sample - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 999/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 1000/1000\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0292 - accuracy: 1.0000\n",
      "[[6.1814400e-04 1.2777947e-03 7.4332934e-03 9.8658770e-01 3.1159397e-03\n",
      "  8.7371973e-07 9.6629409e-04]] [3]\n"
     ]
    }
   ],
   "source": [
    "# Lab 6 Softmax Zoo Classifier\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Predicting animal type based on various features\n",
    "xy=np.loadtxt('../00_data/data-04-zoo.csv',delimiter=',',dtype=np.float32)\n",
    "if xy is None:\n",
    "    print('data load failed')\n",
    "    sys.exit()\n",
    "\n",
    "x_data=xy[:,:-1]\n",
    "y_data=xy[:,[-1]]\n",
    "print(len(x_data[1,:]))\n",
    "# Check data loading is OK\n",
    "# print(x_data)\n",
    "# print(y_data)\n",
    "\n",
    "# y_data 는 0~6 으로 7가지\n",
    "nb_classes=7\n",
    "\n",
    "# y_data를 one hot Encoding 으로 변환 \n",
    "# y_data는 0~6 의 정수로 구성되어있음. 이진분류를 위해 1,0 의 값으로 변환시는 one-hot encoding 사용\n",
    "\"\"\" tf.keras.utils.to_categorical(y, num_classes=None, dtype='float32')\n",
    "Converts a class vector (integers) to binary class matrix.\n",
    " \"\"\"\n",
    "Y_one_hot=tf.keras.utils.to_categorical(y_data,nb_classes)\n",
    "# Model instance stting.\n",
    "tf.model=tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes,input_dim=16,activation='softmax'))\n",
    "# compile : 훈령 과정 설정 - 손실함수 : cross-entropy, 최적화 : Gradient Descent Optimizer 사용, learning rate=0.1)\n",
    "tf.model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.SGD(lr=0.1),metrics=['accuracy'])\n",
    "# fit : 훈련 실행 - epoch만큰 훈련과정 반복\n",
    "tf.model.summary()\n",
    "\n",
    "history=tf.model.fit(x_data,Y_one_hot,epochs=1000)\n",
    "\n",
    "# Single data test\n",
    "test_data=np.array([[0,0,1,0,0,1,1,1,1,0,0,1,0,1,0,0]])\n",
    "# 예상되는 prediction ==3\n",
    "# predict 는 probability를 predict_class 는 label 을 제공한다.\n",
    "print(tf.model.predict(test_data),tf.model.predict_classes(test_data))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y_data.flatten length: 101\n101\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:3 True Y:3\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:3 True Y:3\n[True]Prediction:3 True Y:3\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:1 True Y:1\n[True]Prediction:3 True Y:3\n[True]Prediction:6 True Y:6\n[True]Prediction:6 True Y:6\n[True]Prediction:6 True Y:6\n[True]Prediction:1 True Y:1\n[True]Prediction:0 True Y:0\n[True]Prediction:3 True Y:3\n[True]Prediction:0 True Y:0\n[True]Prediction:1 True Y:1\n[True]Prediction:1 True Y:1\n[True]Prediction:0 True Y:0\n[True]Prediction:1 True Y:1\n[True]Prediction:5 True Y:5\n[True]Prediction:4 True Y:4\n[True]Prediction:4 True Y:4\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:5 True Y:5\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:1 True Y:1\n[True]Prediction:3 True Y:3\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:1 True Y:1\n[True]Prediction:3 True Y:3\n[True]Prediction:5 True Y:5\n[True]Prediction:5 True Y:5\n[True]Prediction:1 True Y:1\n[True]Prediction:5 True Y:5\n[True]Prediction:1 True Y:1\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:6 True Y:6\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:5 True Y:5\n[True]Prediction:4 True Y:4\n[True]Prediction:6 True Y:6\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:1 True Y:1\n[True]Prediction:1 True Y:1\n[True]Prediction:1 True Y:1\n[True]Prediction:1 True Y:1\n[True]Prediction:3 True Y:3\n[True]Prediction:3 True Y:3\n[True]Prediction:2 True Y:2\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:1 True Y:1\n[True]Prediction:6 True Y:6\n[True]Prediction:3 True Y:3\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:2 True Y:2\n[True]Prediction:6 True Y:6\n[True]Prediction:1 True Y:1\n[True]Prediction:1 True Y:1\n[True]Prediction:2 True Y:2\n[True]Prediction:6 True Y:6\n[True]Prediction:3 True Y:3\n[True]Prediction:1 True Y:1\n[True]Prediction:0 True Y:0\n[True]Prediction:6 True Y:6\n[True]Prediction:3 True Y:3\n[True]Prediction:1 True Y:1\n[True]Prediction:5 True Y:5\n[True]Prediction:4 True Y:4\n[True]Prediction:2 True Y:2\n[True]Prediction:2 True Y:2\n[True]Prediction:3 True Y:3\n[True]Prediction:0 True Y:0\n[True]Prediction:0 True Y:0\n[True]Prediction:1 True Y:1\n[True]Prediction:0 True Y:0\n[True]Prediction:5 True Y:5\n[True]Prediction:0 True Y:0\n[True]Prediction:6 True Y:6\n[True]Prediction:1 True Y:1\n"
     ]
    }
   ],
   "source": [
    "# 전체 x_data test\n",
    "\n",
    "\n",
    "pred=tf.model.predict_classes(x_data)\n",
    "print(\"y_data.flatten length:\",len(y_data.flatten()))\n",
    "print(len(pred))\n",
    "for p,y in zip(pred,y_data.flatten()):\n",
    "    print(\"[{}]Prediction:{} True Y:{}\".format(p==int(y),p,int(y)))\n",
    "\n"
   ]
  }
 ]
}