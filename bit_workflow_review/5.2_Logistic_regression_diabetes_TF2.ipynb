{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1601983346444",
   "display_name": "Python 3.6.10 64-bit ('TF2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 5 Logistic Regression Classifier\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "source": [
    "1. Load data\n",
    "2. set model=Sequential()\n",
    "3. add layers as Dense(units,input_dim,activation)\n",
    "    - Dense layer는 입력과 출력을 모두 연결해주며, 입력과 출력을 각각 연결해주는 가중치를 포함하고 있다. 즉, 입력이 4개, 출력이 8개라면 가중치는 32개가 존개한다.\n",
    "    - units:  출력 뉴런의 수를 결정.\n",
    "    - input_dim : 입력 뉴런의 수를 결정\n",
    "    - activation : 활성함수\n",
    "    - 처음에 input_dim을 정해주게 되면 앞의 출력 뉴런의 수에 맞게 출력 뉴런의 수가 정해지므로 input_dim 을 생량할 수 있다.\n",
    "    - 활성함수\n",
    "        - relu : 은닉 층으로 학습 (은닉층으로 역전파를 통해 좋은 성능이 나오므로 마지막 층이 아니고서야 거의 relu를 사용한다.)\n",
    "        - sigmoid : 이진 분류 문제\n",
    "        - softmax : class       \n",
    "        - sigmoid : 이진 분류 문제\n",
    "4. compile(loss,optimizer,metrics)\n",
    "                        \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(759, 8) (759, 1)\n8 759\n"
    }
   ],
   "source": [
    "# 1. Data load & check\n",
    "xy=np.loadtxt('../00_data/data-03-diabetes.csv',delimiter=',',dtype=np.float32)\n",
    "x_data=xy[:,:-1]\n",
    "y_data=xy[:,[-1]]\n",
    "if y_data is None:\n",
    "    print('data load failed')\n",
    "    sys.exit()\n",
    "print(x_data.shape,y_data.shape)\n",
    "print(x_data.shape[1],x_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "9/759 [==============================] - 0s 51us/sample - loss: 0.4893 - accuracy: 0.7655\nEpoch 315/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4892 - accuracy: 0.7655\nEpoch 316/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4891 - accuracy: 0.7655\nEpoch 317/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4890 - accuracy: 0.7655\nEpoch 318/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4889 - accuracy: 0.7655\nEpoch 319/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4889 - accuracy: 0.7655\nEpoch 320/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4888 - accuracy: 0.7655\nEpoch 321/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4887 - accuracy: 0.7655\nEpoch 322/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4886 - accuracy: 0.7655\nEpoch 323/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4885 - accuracy: 0.7655\nEpoch 324/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4884 - accuracy: 0.7655\nEpoch 325/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4884 - accuracy: 0.7655\nEpoch 326/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4883 - accuracy: 0.7668\nEpoch 327/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4882 - accuracy: 0.7668\nEpoch 328/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4881 - accuracy: 0.7668\nEpoch 329/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4881 - accuracy: 0.7655\nEpoch 330/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4880 - accuracy: 0.7668\nEpoch 331/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4879 - accuracy: 0.7655\nEpoch 332/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4878 - accuracy: 0.7655\nEpoch 333/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4878 - accuracy: 0.7655\nEpoch 334/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4877 - accuracy: 0.7668\nEpoch 335/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4876 - accuracy: 0.7655\nEpoch 336/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4875 - accuracy: 0.7642\nEpoch 337/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4875 - accuracy: 0.7642\nEpoch 338/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4874 - accuracy: 0.7655\nEpoch 339/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4874 - accuracy: 0.7655\nEpoch 340/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4873 - accuracy: 0.7655\nEpoch 341/500\n759/759 [==============================] - 0s 79us/sample - loss: 0.4872 - accuracy: 0.7655\nEpoch 342/500\n759/759 [==============================] - 0s 59us/sample - loss: 0.4871 - accuracy: 0.7642\nEpoch 343/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4870 - accuracy: 0.7655\nEpoch 344/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4870 - accuracy: 0.7655\nEpoch 345/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4869 - accuracy: 0.7655\nEpoch 346/500\n759/759 [==============================] - 0s 47us/sample - loss: 0.4869 - accuracy: 0.7655\nEpoch 347/500\n759/759 [==============================] - 0s 70us/sample - loss: 0.4868 - accuracy: 0.7655\nEpoch 348/500\n759/759 [==============================] - 0s 66us/sample - loss: 0.4867 - accuracy: 0.7655\nEpoch 349/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4867 - accuracy: 0.7655\nEpoch 350/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4866 - accuracy: 0.7655\nEpoch 351/500\n759/759 [==============================] - 0s 52us/sample - loss: 0.4865 - accuracy: 0.7655\nEpoch 352/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4865 - accuracy: 0.7642\nEpoch 353/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4864 - accuracy: 0.7668\nEpoch 354/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4863 - accuracy: 0.7655\nEpoch 355/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4863 - accuracy: 0.7655\nEpoch 356/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4862 - accuracy: 0.7642\nEpoch 357/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4861 - accuracy: 0.7655\nEpoch 358/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4861 - accuracy: 0.7655\nEpoch 359/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4860 - accuracy: 0.7655\nEpoch 360/500\n759/759 [==============================] - 0s 58us/sample - loss: 0.4860 - accuracy: 0.7655\nEpoch 361/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4859 - accuracy: 0.7655\nEpoch 362/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4858 - accuracy: 0.7655\nEpoch 363/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4858 - accuracy: 0.7655\nEpoch 364/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4857 - accuracy: 0.7655\nEpoch 365/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4857 - accuracy: 0.7655\nEpoch 366/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4856 - accuracy: 0.7655\nEpoch 367/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4855 - accuracy: 0.7642\nEpoch 368/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4854 - accuracy: 0.7655\nEpoch 369/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4854 - accuracy: 0.7642\nEpoch 370/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4853 - accuracy: 0.7642\nEpoch 371/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4853 - accuracy: 0.7642\nEpoch 372/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4853 - accuracy: 0.7655\nEpoch 373/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4852 - accuracy: 0.7655\nEpoch 374/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4851 - accuracy: 0.7642\nEpoch 375/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4851 - accuracy: 0.7642\nEpoch 376/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4850 - accuracy: 0.7642\nEpoch 377/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4850 - accuracy: 0.7642\nEpoch 378/500\n759/759 [==============================] - 0s 58us/sample - loss: 0.4849 - accuracy: 0.7642\nEpoch 379/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4849 - accuracy: 0.7642\nEpoch 380/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4848 - accuracy: 0.7642\nEpoch 381/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4847 - accuracy: 0.7642\nEpoch 382/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4847 - accuracy: 0.7642\nEpoch 383/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4846 - accuracy: 0.7642\nEpoch 384/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4846 - accuracy: 0.7642\nEpoch 385/500\n759/759 [==============================] - 0s 58us/sample - loss: 0.4845 - accuracy: 0.7655\nEpoch 386/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4845 - accuracy: 0.7642\nEpoch 387/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4844 - accuracy: 0.7642\nEpoch 388/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4843 - accuracy: 0.7642\nEpoch 389/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4843 - accuracy: 0.7642\nEpoch 390/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4843 - accuracy: 0.7642\nEpoch 391/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4842 - accuracy: 0.7628\nEpoch 392/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4842 - accuracy: 0.7642\nEpoch 393/500\n759/759 [==============================] - 0s 58us/sample - loss: 0.4841 - accuracy: 0.7642\nEpoch 394/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4840 - accuracy: 0.7628\nEpoch 395/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4840 - accuracy: 0.7628\nEpoch 396/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4840 - accuracy: 0.7628\nEpoch 397/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4839 - accuracy: 0.7628\nEpoch 398/500\n759/759 [==============================] - 0s 57us/sample - loss: 0.4839 - accuracy: 0.7628\nEpoch 399/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4838 - accuracy: 0.7628\nEpoch 400/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4837 - accuracy: 0.7628\nEpoch 401/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4837 - accuracy: 0.7642\nEpoch 402/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4837 - accuracy: 0.7628\nEpoch 403/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4836 - accuracy: 0.7628\nEpoch 404/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4836 - accuracy: 0.7642\nEpoch 405/500\n759/759 [==============================] - 0s 57us/sample - loss: 0.4835 - accuracy: 0.7628\nEpoch 406/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4835 - accuracy: 0.7642\nEpoch 407/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4834 - accuracy: 0.7628\nEpoch 408/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4834 - accuracy: 0.7628\nEpoch 409/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4834 - accuracy: 0.7628\nEpoch 410/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4833 - accuracy: 0.7615\nEpoch 411/500\n759/759 [==============================] - 0s 76us/sample - loss: 0.4832 - accuracy: 0.7628\nEpoch 412/500\n759/759 [==============================] - 0s 58us/sample - loss: 0.4832 - accuracy: 0.7628\nEpoch 413/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4831 - accuracy: 0.7628\nEpoch 414/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4831 - accuracy: 0.7642\nEpoch 415/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4831 - accuracy: 0.7655\nEpoch 416/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4830 - accuracy: 0.7642\nEpoch 417/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4830 - accuracy: 0.7642\nEpoch 418/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4829 - accuracy: 0.7615\nEpoch 419/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4829 - accuracy: 0.7615\nEpoch 420/500\n759/759 [==============================] - 0s 57us/sample - loss: 0.4828 - accuracy: 0.7615\nEpoch 421/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4828 - accuracy: 0.7655\nEpoch 422/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4828 - accuracy: 0.7642\nEpoch 423/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4827 - accuracy: 0.7668\nEpoch 424/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4827 - accuracy: 0.7668\nEpoch 425/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4826 - accuracy: 0.7642\nEpoch 426/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4826 - accuracy: 0.7655\nEpoch 427/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4825 - accuracy: 0.7655\nEpoch 428/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4825 - accuracy: 0.7642\nEpoch 429/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4824 - accuracy: 0.7655\nEpoch 430/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4824 - accuracy: 0.7655\nEpoch 431/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4824 - accuracy: 0.7655\nEpoch 432/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4823 - accuracy: 0.7668\nEpoch 433/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4823 - accuracy: 0.7655\nEpoch 434/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4822 - accuracy: 0.7655\nEpoch 435/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4822 - accuracy: 0.7655\nEpoch 436/500\n759/759 [==============================] - 0s 59us/sample - loss: 0.4822 - accuracy: 0.7655\nEpoch 437/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4821 - accuracy: 0.7668\nEpoch 438/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4821 - accuracy: 0.7655\nEpoch 439/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4820 - accuracy: 0.7655\nEpoch 440/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4820 - accuracy: 0.7655\nEpoch 441/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4820 - accuracy: 0.7668\nEpoch 442/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4819 - accuracy: 0.7655\nEpoch 443/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4819 - accuracy: 0.7668\nEpoch 444/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4818 - accuracy: 0.7668\nEpoch 445/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4818 - accuracy: 0.7668\nEpoch 446/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4818 - accuracy: 0.7668\nEpoch 447/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4817 - accuracy: 0.7668\nEpoch 448/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4817 - accuracy: 0.7668\nEpoch 449/500\n759/759 [==============================] - 0s 52us/sample - loss: 0.4817 - accuracy: 0.7668\nEpoch 450/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4816 - accuracy: 0.7668\nEpoch 451/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4816 - accuracy: 0.7681\nEpoch 452/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4816 - accuracy: 0.7681\nEpoch 453/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4815 - accuracy: 0.7668\nEpoch 454/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4815 - accuracy: 0.7681\nEpoch 455/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4814 - accuracy: 0.7681\nEpoch 456/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4814 - accuracy: 0.7681\nEpoch 457/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4813 - accuracy: 0.7681\nEpoch 458/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4813 - accuracy: 0.7681\nEpoch 459/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4813 - accuracy: 0.7681\nEpoch 460/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4813 - accuracy: 0.7681\nEpoch 461/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4812 - accuracy: 0.7681\nEpoch 462/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4812 - accuracy: 0.7681\nEpoch 463/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4811 - accuracy: 0.7681\nEpoch 464/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4811 - accuracy: 0.7681\nEpoch 465/500\n759/759 [==============================] - 0s 87us/sample - loss: 0.4811 - accuracy: 0.7681\nEpoch 466/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4810 - accuracy: 0.7681\nEpoch 467/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4810 - accuracy: 0.7681\nEpoch 468/500\n759/759 [==============================] - 0s 49us/sample - loss: 0.4810 - accuracy: 0.7681\nEpoch 469/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4810 - accuracy: 0.7681\nEpoch 470/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4809 - accuracy: 0.7681\nEpoch 471/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4809 - accuracy: 0.7681\nEpoch 472/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4808 - accuracy: 0.7681\nEpoch 473/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4808 - accuracy: 0.7681\nEpoch 474/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4808 - accuracy: 0.7681\nEpoch 475/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4808 - accuracy: 0.7681\nEpoch 476/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4807 - accuracy: 0.7681\nEpoch 477/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4807 - accuracy: 0.7681\nEpoch 478/500\n759/759 [==============================] - 0s 57us/sample - loss: 0.4807 - accuracy: 0.7681\nEpoch 479/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4806 - accuracy: 0.7681\nEpoch 480/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4806 - accuracy: 0.7681\nEpoch 481/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4806 - accuracy: 0.7681\nEpoch 482/500\n759/759 [==============================] - 0s 47us/sample - loss: 0.4805 - accuracy: 0.7681\nEpoch 483/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4805 - accuracy: 0.7681\nEpoch 484/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4805 - accuracy: 0.7681\nEpoch 485/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4804 - accuracy: 0.7681\nEpoch 486/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4804 - accuracy: 0.7681\nEpoch 487/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4804 - accuracy: 0.7681\nEpoch 488/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4803 - accuracy: 0.7681\nEpoch 489/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4803 - accuracy: 0.7681\nEpoch 490/500\n759/759 [==============================] - 0s 54us/sample - loss: 0.4803 - accuracy: 0.7681\nEpoch 491/500\n759/759 [==============================] - 0s 50us/sample - loss: 0.4802 - accuracy: 0.7681\nEpoch 492/500\n759/759 [==============================] - 0s 53us/sample - loss: 0.4802 - accuracy: 0.7681\nEpoch 493/500\n759/759 [==============================] - 0s 51us/sample - loss: 0.4802 - accuracy: 0.7681\nEpoch 494/500\n759/759 [==============================] - 0s 55us/sample - loss: 0.4802 - accuracy: 0.7681\nEpoch 495/500\n759/759 [==============================] - 0s 62us/sample - loss: 0.4802 - accuracy: 0.7681\nEpoch 496/500\n759/759 [==============================] - 0s 65us/sample - loss: 0.4801 - accuracy: 0.7694\nEpoch 497/500\n759/759 [==============================] - 0s 62us/sample - loss: 0.4801 - accuracy: 0.7681\nEpoch 498/500\n759/759 [==============================] - 0s 63us/sample - loss: 0.4801 - accuracy: 0.7655\nEpoch 499/500\n759/759 [==============================] - 0s 65us/sample - loss: 0.4800 - accuracy: 0.7694\nEpoch 500/500\n759/759 [==============================] - 0s 59us/sample - loss: 0.4800 - accuracy: 0.7681\nAccuracy:0.7681159377098083\nPredic:[[0.60035884]]\n759/759 [==============================] - 0s 213us/sample - loss: 0.4799 - accuracy: 0.7681\nloss0.4799185199699854,accuracy:0.7681159377098083\n"
    }
   ],
   "source": [
    "# 2. model set = Sequential()\n",
    "tf.model=Sequential()\n",
    "tf.model.add(Dense(units=1,input_dim=x_data.shape[1],activation='sigmoid'))\n",
    "tf.model.compile(loss='binary_crossentropy',optimizer=SGD(lr=0.01),metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "history=tf.model.fit(x_data,y_data,epochs=500)\n",
    "\n",
    "#accuracy\n",
    "print('Accuracy:{0}'.format(history.history['accuracy'][-1]))\n",
    "\n",
    "#predict a single data point\n",
    "y_predic=tf.model.predict([[0.176471,0.155779,0,0,0,0.052161,-0.952178,-0.733333]])\n",
    "print(\"Predic:{0}\".format(y_predic))\n",
    "\n",
    "# evaluating model\n",
    "evaluate=tf.model.evaluate(x_data,y_data)\n",
    "print('loss{0},accuracy:{1}'.format(evaluate[0],evaluate[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}