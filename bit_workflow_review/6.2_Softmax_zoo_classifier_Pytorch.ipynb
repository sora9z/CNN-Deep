{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.10 64-bit ('TF2': conda)",
   "display_name": "Python 3.6.10 64-bit ('TF2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "0852b15a40ba772cc6cccde9ee3e0692fec73481972f7fa88d7df0aedb40ab85"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(101, 16) (101, 1)\n",
      "one_hot tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0.]])\n",
      "Step:    0\tLoss:2.124\tAcc:8.89%\n",
      "Step:  100\tLoss:0.462\tAcc:25.49%\n",
      "Step:  200\tLoss:0.312\tAcc:24.47%\n",
      "Step:  300\tLoss:0.241\tAcc:24.47%\n",
      "Step:  400\tLoss:0.198\tAcc:24.27%\n",
      "Step:  500\tLoss:0.169\tAcc:24.19%\n",
      "Step:  600\tLoss:0.147\tAcc:24.21%\n",
      "Step:  700\tLoss:0.131\tAcc:24.21%\n",
      "Step:  800\tLoss:0.118\tAcc:24.07%\n",
      "Step:  900\tLoss:0.107\tAcc:24.07%\n",
      "Step: 1000\tLoss:0.098\tAcc:24.07%\n",
      "Step: 1100\tLoss:0.091\tAcc:24.07%\n",
      "Step: 1200\tLoss:0.085\tAcc:24.07%\n",
      "Step: 1300\tLoss:0.079\tAcc:24.07%\n",
      "Step: 1400\tLoss:0.074\tAcc:24.07%\n",
      "Step: 1500\tLoss:0.070\tAcc:24.07%\n",
      "Step: 1600\tLoss:0.066\tAcc:24.07%\n",
      "Step: 1700\tLoss:0.063\tAcc:24.07%\n",
      "Step: 1800\tLoss:0.059\tAcc:24.07%\n",
      "Step: 1900\tLoss:0.057\tAcc:24.07%\n",
      "Step: 2000\tLoss:0.054\tAcc:24.07%\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:3.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:3.0 True Y:[0.]\n",
      "[True]Prediction:3.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:3.0 True Y:[0.]\n",
      "[True]Prediction:6.0 True Y:[0.]\n",
      "[True]Prediction:6.0 True Y:[0.]\n",
      "[True]Prediction:6.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:3.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:5.0 True Y:[0.]\n",
      "[True]Prediction:4.0 True Y:[0.]\n",
      "[True]Prediction:4.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:5.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:3.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:3.0 True Y:[0.]\n",
      "[True]Prediction:5.0 True Y:[0.]\n",
      "[True]Prediction:5.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:5.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:6.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:5.0 True Y:[0.]\n",
      "[True]Prediction:4.0 True Y:[0.]\n",
      "[True]Prediction:6.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:3.0 True Y:[0.]\n",
      "[True]Prediction:3.0 True Y:[0.]\n",
      "[True]Prediction:2.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:6.0 True Y:[0.]\n",
      "[True]Prediction:3.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:2.0 True Y:[0.]\n",
      "[True]Prediction:6.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:2.0 True Y:[0.]\n",
      "[True]Prediction:6.0 True Y:[0.]\n",
      "[True]Prediction:3.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:6.0 True Y:[0.]\n",
      "[True]Prediction:3.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:5.0 True Y:[0.]\n",
      "[True]Prediction:4.0 True Y:[0.]\n",
      "[True]Prediction:2.0 True Y:[0.]\n",
      "[True]Prediction:2.0 True Y:[0.]\n",
      "[True]Prediction:3.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:5.0 True Y:[0.]\n",
      "[True]Prediction:0.0 True Y:[0.]\n",
      "[True]Prediction:6.0 True Y:[0.]\n",
      "[True]Prediction:1.0 True Y:[0.]\n"
     ]
    }
   ],
   "source": [
    "# Lab 6 Sotfmax zoo classifier\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Set random Seed\n",
    "torch.manual_seed(111)\n",
    "\n",
    "# 1. Data loading\n",
    "xy=np.loadtxt('../00_data/data-04-zoo.csv',delimiter=',',dtype=np.float32)\n",
    "x_data=xy[:,:-1]\n",
    "y_data=xy[:,[-1]]\n",
    "\n",
    "print(x_data.shape,y_data.shape)\n",
    "nb_classes=7\n",
    "\n",
    "# ndarray를 torch variable 로 변형\n",
    "X=Variable(torch.from_numpy(x_data))\n",
    "Y=Variable(torch.from_numpy(y_data))\n",
    "\n",
    "# 2. one_hot encoding : 이진분류 문제이므로,0~6 사이의 정수값을 갖는 Y를 one-hot encoding 하여 이진분류\n",
    "\n",
    "Y_one_hot=torch.zeros(Y.size()[0],nb_classes) # 101,7 크기의 torch list를 0으로 채운 torch list return\n",
    "Y_one_hot.scatter_(1,Y.long().data,1) # self.long()`` is equivalent to ``self.to(torch.int64)``.\n",
    "Y_one_hot=Variable(Y_one_hot)\n",
    "print(\"one_hot\",Y_one_hot.data)\n",
    "\n",
    "# 3. Model instance 생성\n",
    "softmax=torch.nn.Softmax()\n",
    "model=torch.nn.Linear(16,nb_classes,bias=True)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "criterion=torch.nn.CrossEntropyLoss() # Softmax is internally computed\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "# 4. Model Train\n",
    "\n",
    "for step in range(2001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis=model(X)\n",
    "    # Label has to be 1D Long Tensor\n",
    "    # : Y.long()을 사용하여 64bit long int type으로 변환.\n",
    "    cost=criterion(hypothesis,Y.long().view(-1)) \n",
    "    # view는 차원 재구성. reshape()과 같이 차원을 재구서하는 매소드. Y.long() 의 배열은 1차원배열로 출력.\n",
    "    # Y.size() ==> (101,1) Y.view(-1).size() ==> (101) \n",
    "    # (EX) \n",
    "    # Y.view(1,2,3) Y.reshape(1,2,3) 처럼 변경하고싶은 shape을 tuple로 입렵. \n",
    "    # view는 기존의 데이터와 같은 메모리 공간을 공유.\n",
    "    # view(-1) 은 reshape(-1) 과 같이 1차원의 배열을 반환함.\n",
    "    \n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "# 5. Ptrdiction\n",
    "    prediction=torch.max(softmax(hypothesis),1)[1].float()\n",
    "    '''\n",
    "    torch.max 함수 \n",
    "    - 주어진 tensor 배열의 최댓값이 들어있는 index를 리턴하는 함수\n",
    "    - Y_pred=[[0.3,0.2,0.9,0.1]] 의 경우 torch.max(Y_pred.data,1) 의 결과는 0.9의 인덱스인 2가 된다.\n",
    "    - 뒤에 들어가는 1은 dimmension에 대한 것.\n",
    "    '''    \n",
    "    correct_prediction=(prediction.data==Y.data) # 예측값인 prediction 와 실측값인 Y가 같으면 1을 반환\n",
    "    accuracy=correct_prediction.float().mean() # Prediction의 평균을 구하여 정확도를 반환.\n",
    "\n",
    "    if step%100==0:\n",
    "        print(\"Step:{:5}\\tLoss:{:.3f}\\tAcc:{:.2%}\".format(step,cost.data,accuracy))\n",
    "# Let's see if we can preidct\n",
    "pred=torch.max(softmax(hypothesis),1)[1].float()\n",
    "for p,y in zip(pred,Y):\n",
    "    print(\"[{}]Prediction:{} True Y:{}\".format(bool(p.data==y.data),p.data,y_data[0]))\n",
    "\n"
   ]
  },
  {
   "source": [
    "https://kjhov195.github.io/2020-01-04-softmax_classifier_2/</br>\n",
    "\n",
    "Cross Entropy : https://medium.com/data-science-bootcamp/understand-cross-entropy-loss-in-minutes-9fb263caee9a\n",
    "\n",
    "</br> \n",
    "https://nuguziii.github.io/paper-review/PR-001/\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([101, 1])\ntorch.Size([101])\ntensor([0., 0., 3., 0., 0., 0., 0., 3., 3., 0., 0., 1., 3., 6., 6., 6., 1., 0.,\n        3., 0., 1., 1., 0., 1., 5., 4., 4., 0., 0., 0., 5., 0., 0., 1., 3., 0.,\n        0., 1., 3., 5., 5., 1., 5., 1., 0., 0., 6., 0., 0., 0., 0., 5., 4., 6.,\n        0., 0., 1., 1., 1., 1., 3., 3., 2., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n        6., 3., 0., 0., 2., 6., 1., 1., 2., 6., 3., 1., 0., 6., 3., 1., 5., 4.,\n        2., 2., 3., 0., 0., 1., 0., 5., 0., 6., 1.])\n-------------------------------\ntensor([[0],\n        [0],\n        [3],\n        [0],\n        [0],\n        [0],\n        [0],\n        [3],\n        [3],\n        [0],\n        [0],\n        [1],\n        [3],\n        [6],\n        [6],\n        [6],\n        [1],\n        [0],\n        [3],\n        [0],\n        [1],\n        [1],\n        [0],\n        [1],\n        [5],\n        [4],\n        [4],\n        [0],\n        [0],\n        [0],\n        [5],\n        [0],\n        [0],\n        [1],\n        [3],\n        [0],\n        [0],\n        [1],\n        [3],\n        [5],\n        [5],\n        [1],\n        [5],\n        [1],\n        [0],\n        [0],\n        [6],\n        [0],\n        [0],\n        [0],\n        [0],\n        [5],\n        [4],\n        [6],\n        [0],\n        [0],\n        [1],\n        [1],\n        [1],\n        [1],\n        [3],\n        [3],\n        [2],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [1],\n        [6],\n        [3],\n        [0],\n        [0],\n        [2],\n        [6],\n        [1],\n        [1],\n        [2],\n        [6],\n        [3],\n        [1],\n        [0],\n        [6],\n        [3],\n        [1],\n        [5],\n        [4],\n        [2],\n        [2],\n        [3],\n        [0],\n        [0],\n        [1],\n        [0],\n        [5],\n        [0],\n        [6],\n        [1]])\ntensor([[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14],\n        [15, 16, 17, 18, 19],\n        [20, 21, 22, 23, 24],\n        [25, 26, 27, 28, 29]], dtype=torch.int32)\ntorch.return_types.max(\nvalues=tensor([25, 26, 27, 28, 29], dtype=torch.int32),\nindices=tensor([5, 5, 5, 5, 5]))\ntorch.return_types.max(\nvalues=tensor([ 4,  9, 14, 19, 24, 29], dtype=torch.int32),\nindices=tensor([4, 4, 4, 4, 4, 4]))\n-----------------------------------------\ntensor([25, 26, 27, 28, 29], dtype=torch.int32)\ntensor([5, 5, 5, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# view매서드의 이해를 위한 test\n",
    "print(Y.size())\n",
    "#print(Y)\n",
    "print(Y.view(-1).size())\n",
    "print(Y.view(-1))\n",
    "print(\"-------------------------------\")\n",
    "print(Y.long())\n",
    "\n",
    "\n",
    "# max 매서드의 이해를 위한 test \n",
    "test_np=np.array(range(30)).reshape(6,5)\n",
    "test_tr=Variable(torch.from_numpy(test_np))\n",
    "\n",
    "print(test_tr.data)\n",
    "print(torch.max(test_tr,0)) # 0은 2차원 배열의 각 행의 최댓값의 값과 index를 반환해준다.\n",
    "print(torch.max(test_tr,1)) # 1은 2차원 배열의 각 열의 최댓값의 값과 index를 반환해 준다.\n",
    "print('-----------------------------------------')\n",
    "print(torch.max(test_tr,0)[0]) # [0] 은 값과 dtype을\n",
    "print(torch.max(test_tr,0)[1]) # [1] 은 index를 반환한다.\n",
    "\n",
    "\n"
   ]
  }
 ]
}